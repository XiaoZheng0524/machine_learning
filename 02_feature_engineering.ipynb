{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 特征提取\n",
    "将任意数据（文本、图像等）转换为可用于机器学习的数字特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 字典特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[  0.   1.   0. 100.]\n",
      " [  1.   0.   0.  60.]\n",
      " [  0.   0.   1.  30.]] <class 'scipy.sparse._csr.csr_matrix'>\n",
      "特征名字：\n",
      " ['city=上海' 'city=北京' 'city=深圳' 'temperature']\n"
     ]
    }
   ],
   "source": [
    "data = [{'city': '北京','temperature':100}, \n",
    "        {'city': '上海','temperature':60}, \n",
    "        {'city': '深圳','temperature':30}]\n",
    "\n",
    "# 1、实例化一个转换器类\n",
    "transfer = DictVectorizer(sparse=True)\n",
    "\n",
    "# 2、调用fit_transform()\n",
    "data_new = transfer.fit_transform(data)\n",
    "print(\"data_new:\\n\", data_new.toarray(), type(data_new))\n",
    "print(\"特征名字：\\n\", transfer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 文本特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 CountVectorizer: 统计词频, 忽略单个字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[0 1 1 0 1 1]\n",
      " [1 1 0 1 1 0]]\n",
      "特征名字：\n",
      " ['dislike' 'life' 'like' 'long' 'python' 'short']\n"
     ]
    }
   ],
   "source": [
    "data = [\"Life is short,I like python\", \"Life is too long,I dislike python\"]\n",
    "\n",
    "# 1、实例化一个转换器类, stop_words为停用词，剔除一些无用词\n",
    "transfer = CountVectorizer(stop_words=[\"is\", \"too\"])\n",
    "\n",
    "# 2、调用fit_transform\n",
    "data_new = transfer.fit_transform(data)\n",
    "print(\"data_new:\\n\", data_new.toarray())\n",
    "print(\"特征名字：\\n\", transfer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[0 1]\n",
      " [1 0]]\n",
      "特征名字：\n",
      " ['天安门上太阳升' '我爱北京天安门']\n"
     ]
    }
   ],
   "source": [
    "# 中文文本数据如果不采用空格或符号分开，会将一整个句子当作一个字\n",
    "data = [\"我爱北京天安门\", \"天安门上太阳升\"]\n",
    "# 1、实例化一个转换器类\n",
    "transfer = CountVectorizer()\n",
    "\n",
    "# 2、调用fit_transform\n",
    "data_new = transfer.fit_transform(data)\n",
    "print(\"data_new:\\n\", data_new.toarray())\n",
    "print(\"特征名字：\\n\", transfer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[1 1 0]\n",
      " [0 1 1]]\n",
      "特征名字：\n",
      " ['北京' '天安门' '太阳']\n"
     ]
    }
   ],
   "source": [
    "# 需要对中文句子进行分词处理\n",
    "data = [\"我 爱 北京 天安门\", \"天安门 上 太阳 升\"]\n",
    "# 1、实例化一个转换器类\n",
    "transfer = CountVectorizer()\n",
    "\n",
    "# 2、调用fit_transform\n",
    "data_new = transfer.fit_transform(data)\n",
    "print(\"data_new:\\n\", data_new.toarray())\n",
    "print(\"特征名字：\\n\", transfer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.435 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 1 0]\n",
      " [0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 0 1]\n",
      " [1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0 0]]\n",
      "特征名字：\n",
      " ['不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个' '看到'\n",
      " '真正' '秘密' '绝对' '美好' '联系' '过去' '还是' '这样']\n"
     ]
    }
   ],
   "source": [
    "# 使用jieba自动分词\n",
    "import jieba\n",
    "data = [\"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\",\n",
    "        \"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\",\n",
    "        \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\"]\n",
    "\n",
    "# 1、分词\n",
    "data_new = []\n",
    "for i in range(len(data)):\n",
    "    data_new.append(' '.join(list(jieba.cut(data[i]))))\n",
    "\n",
    "transfer = CountVectorizer(stop_words=[\"一种\", \"所以\"])\n",
    "\n",
    "# 2、调用fit_transform\n",
    "data_final = transfer.fit_transform(data_new)\n",
    "print(\"data_new:\\n\", data_final.toarray())\n",
    "print(\"特征名字：\\n\", transfer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 TfidfVectorizer: \n",
    "- tf: term frequency,词频=某个词在该文本中出现的次数/该文本中所有词的总数\n",
    "- idf: inverse document frequency,逆向文档频率=log10(总文件数目/包含该词语的文件数)\n",
    "- tf*idf: 希望词在一个类别文章中出现的频率很高，在其他类别的文章中那个出现的频率很低,以便于得到更具有代表性的关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[0.         0.21821789 0.         0.         0.         0.43643578\n",
      "  0.         0.         0.         0.         0.         0.21821789\n",
      "  0.         0.21821789 0.         0.         0.         0.\n",
      "  0.21821789 0.         0.43643578 0.         0.21821789 0.\n",
      "  0.43643578 0.21821789 0.         0.         0.         0.21821789\n",
      "  0.21821789 0.         0.         0.21821789 0.        ]\n",
      " [0.         0.         0.2410822  0.         0.         0.\n",
      "  0.2410822  0.2410822  0.2410822  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.2410822  0.55004769\n",
      "  0.         0.         0.         0.2410822  0.         0.\n",
      "  0.         0.         0.48216441 0.         0.         0.\n",
      "  0.         0.         0.2410822  0.         0.2410822 ]\n",
      " [0.15895379 0.         0.         0.63581516 0.47686137 0.\n",
      "  0.         0.         0.         0.15895379 0.15895379 0.\n",
      "  0.15895379 0.         0.15895379 0.15895379 0.         0.12088845\n",
      "  0.         0.15895379 0.         0.         0.         0.15895379\n",
      "  0.         0.         0.         0.31790758 0.15895379 0.\n",
      "  0.         0.15895379 0.         0.         0.        ]]\n",
      "特征名字：\n",
      " ['不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个' '看到'\n",
      " '真正' '秘密' '绝对' '美好' '联系' '过去' '还是' '这样']\n"
     ]
    }
   ],
   "source": [
    "data = [\"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\",\n",
    "        \"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\",\n",
    "        \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\"]\n",
    "\n",
    "# 1、分词\n",
    "data_new = []\n",
    "for i in range(len(data)):\n",
    "    data_new.append(' '.join(list(jieba.cut(data[i]))))\n",
    "\n",
    "transfer = TfidfVectorizer(stop_words=[\"一种\", \"所以\"])\n",
    "\n",
    "# 2、调用fit_transform\n",
    "data_final = transfer.fit_transform(data_new)\n",
    "print(\"data_new:\\n\", data_final.toarray())\n",
    "print(\"特征名字：\\n\", transfer.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
